{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2023-03-11 20:27:44\n",
      "Here is a list of non ASCII characters:\n",
      "[]\n",
      "Here is a list of loose characters to clean up:\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "~~~REPLACING LOOSE CHARACTERS~~~\n",
      "Here is the cleaned up list of loose characters :\n",
      "[]\n",
      "~~~PRINTING CONTENTS TO FINAL.TXT~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Finished ripping quotes at: 2023-03-11 20:29:53\n",
      "Elapsed time: 0.7 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "nowstart = datetime.datetime.now()\n",
    "print(\"start time:\", now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "word = 'Marcus Aurelius'\n",
    "url = 'https://en.wikiquote.org/w/index.php?action=edit&title=' + word\n",
    "\n",
    "#specific to wikiquote, the lines will start with text you want to remove\n",
    "prefixes_to_remove = [\n",
    "    '* I',\n",
    "    '** I',\n",
    "    '*** I',\n",
    "    '**** I',\n",
    "    '* V',\n",
    "    '** V',\n",
    "    '*** V',\n",
    "    '**** V',\n",
    "    '* X',\n",
    "    '** X',\n",
    "    '*** X',\n",
    "    '**** X'\n",
    "]\n",
    "\n",
    "# Get the page content and extract quotes\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "quotes = soup.text\n",
    "quotes = re.sub(\"===([a-z]|[A-Z]|\\s|[0-9]|[\\\\'-_@!#$<>%&\\\\(\\\\)\\\\[\\\\]])*===\", \"<hr width=\\\"50%\\\"/>\\n\", quotes)\n",
    "quotes = re.sub(\"\\\\[\\\\[w:([a-z]|[A-Z]|\\s|[0-9]|[\\\\'-_@!#$%&\\\\(\\\\)\\\\[\\\\]])*\\\\|\", \"\", quotes)\n",
    "quotes = re.sub(\"\\\\]\\\\]\", \"\", quotes)\n",
    "quotes = re.sub(\"\\\\:\\'\\'\\'\", \"<b>\", quotes)\n",
    "quotes = re.sub(\"=\\s\", \"=\", quotes)\n",
    "quotes = re.sub(\"\\s=\", \"=\", quotes)\n",
    "quotes = re.sub(\"\\n\\n\", \"\\n\", quotes)\n",
    "quotes = re.sub(\"\\n\\n\", \"\\n\", quotes)\n",
    "quotes = re.sub(\"<\\s\", \"<\", quotes)\n",
    "quotes = re.sub(\"\\s>\", \">\", quotes)\n",
    "quotes = re.sub(\"\\'\\'\\'\", \"<b>\", quotes)\n",
    "quotes = re.sub(\"\\\\:\\'\\'\", \"<i>\", quotes)\n",
    "quotes = re.sub(\"\\'\\'\", \"<i>\", quotes)\n",
    "extracted = re.sub(\"\\\\<hr width=\\\"50\\\\%\\\"\\\\/>\\\\n\", \"%%%%\\n\\n\", quotes)\n",
    "extracted = re.split(\"%%%%\\n\", extracted)\n",
    "extracted.remove(extracted[-1])\n",
    "extracted.remove(extracted[0])\n",
    "\n",
    "# Write extracted quotes to txt file in local folder\n",
    "with open('extract.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(extracted)\n",
    "\n",
    "quotes = re.sub(\"\\\\<hr width=\\\"50\\\\%\\\"\\\\/>\\\\n\", f\"\\n - {word.replace('_', ' ')}\\n%%%%\\n%\\n\", quotes)\n",
    "quotes = re.sub(\"<b>\", \"\", quotes)\n",
    "quotes = re.sub(\"<i>\", \"\", quotes)\n",
    "quotes = re.split(\"%%%%\\n\", quotes)\n",
    "quotes.remove(quotes[-1])\n",
    "quotes.remove(quotes[0])\n",
    "quotes[0] = quotes[0].replace('%\\n', '')\n",
    "\n",
    "# Write extracted quotes to txt file in local folder\n",
    "with open('extract.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(extracted)\n",
    "\n",
    "# Open the extracted quote file for reading\n",
    "with open('extract.txt', 'r', encoding='iso-8859-1') as infile:\n",
    "    # Read in the contents of the file\n",
    "    text = infile.read()\n",
    "\n",
    "# Clean quotes in extracted file\n",
    "text = re.sub(r'<.*?>|\\S*\\.jpg\\S*|\\S*#\\S*', '', text)\n",
    "text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "text = re.sub(r'\\s+\\S*:\\S+\\s+|\\S+:\\S+\\s+|\\s+\\S*:\\S+', '', text)\n",
    "text = re.sub(r'\\([^()]*\\)', '', text)\n",
    "text = re.sub(r'^[^\\r\\na-zA-Z]*[^\\r\\na-zA-Z\\s]+[^\\r\\na-zA-Z]*$|^\\s*$', '', text, flags=re.MULTILINE)\n",
    "text = text.replace('[', '')\n",
    "text = text.replace(']', '')\n",
    "\n",
    "# Open the cleaned sentences output file for writing\n",
    "with open('cleaned_sentences.txt', 'w', encoding='utf-8') as outfile:\n",
    "# Write the modified text to the output file\n",
    "    outfile.write(text)\n",
    "\n",
    "# Open the cleaned sentences file for reading\n",
    "with open('cleaned_sentences.txt', 'r', encoding='iso-8859-1') as infile:\n",
    "    # Read in the contents of the file\n",
    "    text = infile.readlines()\n",
    "\n",
    "# Remove unwanted lines from text based on the dictionary at the start of the code\n",
    "for prefix in prefixes_to_remove:\n",
    "    text = [line for line in text if not line.startswith(prefix)]\n",
    "text = [line for line in text if '|' not in line]\n",
    "\n",
    "\n",
    "# Clean text and write to file - this edits the start of lines where the prior code removes entire pointless lines\n",
    "text = [line.strip() for line in text if line.strip() != '']\n",
    "text = '\\n\\n'.join(text) + '\\n'\n",
    "text = text.replace('[', '')\n",
    "text = text.replace(']', '')\n",
    "text = text.replace('*', '')\n",
    "text = text.replace('** ', '')\n",
    "text = text.replace('*** ', '')\n",
    "text = text.replace('**** ', '')\n",
    "text = re.sub(r'^\\s+', '', text, flags=re.MULTILINE)\n",
    "text = text.replace(\"\\n\", \"\\n\\n\")\n",
    "\n",
    "\n",
    "with open('cleaned_sentences.txt', 'w', encoding='utf-8') as outfile:\n",
    "    # Write the modified text to the output file\n",
    "    outfile.write(text)\n",
    "\n",
    "with open('cleaned_sentences.txt', 'r', encoding='utf-8') as infile:\n",
    "    # Read in the contents of the file\n",
    "    text = infile.read()\n",
    "\n",
    "\n",
    "# Find all non-ASCII characters in the text\n",
    "non_ascii_chars = re.findall('[^\\x00-\\x7F]', text)\n",
    "\n",
    "# Print the list of non-ASCII characters to terminal\n",
    "print(\"Here is a list of non ASCII characters:\")\n",
    "print(non_ascii_chars)\n",
    "\n",
    "with open('cleaned_sentences.txt', 'r', encoding='utf-8') as infile:\n",
    "    # Read in the contents of the file\n",
    "    text = infile.read()\n",
    "\n",
    "#find any loose characters that are not single letter words\n",
    "pattern = r\"\\b(?!(a|i)\\b)\\w\\b\"\n",
    "\n",
    "x = re.findall(pattern, text, re.IGNORECASE)\n",
    "print(\"Here is a list of loose characters to clean up:\")\n",
    "print(x)\n",
    "\n",
    "# Open the input file for reading\n",
    "with open(\"cleaned_sentences.txt\", \"r\") as input_file:\n",
    "    # Read the contents of the input file\n",
    "    contents = input_file.read()\n",
    "\n",
    "# Define the regular expression to find words that are one character long (excluding \"a\" and \"i\")\n",
    "pattern = r\"\\b(?!(a|i)\\b)\\w\\b\"\n",
    "\n",
    "print(\"~~~REPLACING LOOSE CHARACTERS~~~\")\n",
    "# Replace any matches with an empty string\n",
    "modified_contents = re.sub(pattern, \"\", contents, flags=re.IGNORECASE)\n",
    "\n",
    "# Open the output file for writing\n",
    "with open(\"cleaned_sentences.txt\", \"w\") as output_file:\n",
    "    # Write the modified contents to the output file\n",
    "    output_file.write(modified_contents)\n",
    "\n",
    "\n",
    "with open('cleaned_sentences.txt', 'r', encoding='utf-8') as infile:\n",
    "    # Read in the contents of the file\n",
    "    text = infile.read()\n",
    "\n",
    "\n",
    "pattern = r\"\\b(?!(a|i)\\b)\\w\\b\"\n",
    "\n",
    "x = re.findall(pattern, text, re.IGNORECASE)\n",
    "print(\"Here is the cleaned up list of loose characters :\")\n",
    "print(x)\n",
    "\n",
    "\n",
    "# Open the input file for reading\n",
    "with open('cleaned_sentences.txt', \"r\") as input_file:\n",
    "    # Read the contents of the input file\n",
    "    contents = input_file.readlines()\n",
    "\n",
    "# Filter out lines shorter than 10 characters\n",
    "filtered_contents = [line for line in contents if len(line.strip()) >= 10]\n",
    "\n",
    "# Add an empty line between each line of text\n",
    "filtered_contents = \"\\n\".join(filtered_contents).replace(\"\\n\", \"\\n\\n\")\n",
    "\n",
    "# Open the output file for writing\n",
    "print(\"~~~PRINTING CONTENTS TO FINAL.TXT~~~\")\n",
    "with open('final.txt', \"w\") as output_file:\n",
    "    # Write the filtered contents to the output file\n",
    "    output_file.writelines(filtered_contents)\n",
    "\n",
    "nowstop = datetime.datetime.now()\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Finished ripping quotes at:\", nowstop.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "elapsed_time = nowstop - nowstart\n",
    "elapsed_seconds = elapsed_time.total_seconds()\n",
    "\n",
    "if elapsed_seconds >= 86400:\n",
    "    elapsed_value = elapsed_seconds / 86400\n",
    "    elapsed_unit = \"day\"\n",
    "elif elapsed_seconds >= 3600:\n",
    "    elapsed_value = elapsed_seconds / 3600\n",
    "    elapsed_unit = \"hour\"\n",
    "elif elapsed_seconds >= 60:\n",
    "    elapsed_value = elapsed_seconds / 60\n",
    "    elapsed_unit = \"minute\"\n",
    "else:\n",
    "    elapsed_value = elapsed_seconds\n",
    "    elapsed_unit = \"second\"\n",
    "\n",
    "elapsed_str = f\"{elapsed_value:.1f} {elapsed_unit}\"\n",
    "if elapsed_value != 1:\n",
    "    elapsed_str += \"s\"\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_str}\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "85322dc11dc870a2b7cb7a80ff056721520541750d6deba2ae6c8f28882ca921"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
